{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl4+FVEtpGTou6/yKQHdxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rong4ivy/AgentBench/blob/main/compare_LLM_langsmith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrvpJAlbCqND"
      },
      "outputs": [],
      "source": [
        "!pip install -U  langchain langsmith openai\n",
        "!pip install -U  langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import OpenAI, HuggingFaceHub\n",
        "from langsmith import Client\n",
        "from langsmith.evaluation import evaluate\n",
        "\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"  # Replace with your OpenAI API key\n",
        "# Set your Groq API key\n",
        "os.environ['GROQ_API_KEY'] = \"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\"\n",
        "os.environ['DEEPSEEK_API_KEY'] = \"sk-1b22df9504bb4de8b0ecab4af9736a43\"\n",
        "os.environ['LLAMA_API_KEY']= \"LL-NvPlk1hPGRjLyA7SFKVQYghNwI8HZujwnk4FEgUf9YEW9wI1c7Vc3szQUPDbryQ0\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"  # Update with your API key\n"
      ],
      "metadata": {
        "id": "x3EtYzVUC93Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare dataset"
      ],
      "metadata": {
        "id": "UOovgAcSdQt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "\n",
        "from langsmith import Client\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the LangSmith client\n",
        "client = Client()\n",
        "\n",
        "# Load the CSV dataset\n",
        "csv_file_path = \"/Spar_test.csv\"  # Replace with your CSV file path\n",
        "df= pd.read_csv(csv_file_path)\n",
        "# Upload the dataset\n",
        "try:\n",
        "    dataset = client.upload_csv(\n",
        "        csv_file=csv_file_path,\n",
        "        input_keys=[\"Story\", \"Question\", \"Candidate_Answers\"],  # Adjust based on your CSV structure\n",
        "        output_keys=[\"Answer\"],\n",
        "        name=\"Spar_human_Dataset\"\n",
        "    )\n",
        "    print(\"Dataset uploaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading dataset: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVPXpgmAeIf1",
        "outputId": "328d5444-d1fd-4a48-ec96-3823894d92c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset uploaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_model_answer(model, question, options):\n",
        "    prompt = f\"{question}\\nOptions: {', '.join(options)}\\nAnswer:\"\n",
        "    response = model(prompt)\n",
        "    return response.strip()  # Clean up the response"
      ],
      "metadata": {
        "id": "PviIw4irZS0C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(models, dataset):\n",
        "    results = []\n",
        "    for item in dataset.inputs:\n",
        "        question = item[\"question\"]\n",
        "        options = item[\"options\"]\n",
        "\n",
        "        for model in models:\n",
        "            model_answer = get_model_answer(model, question, options)\n",
        "            results.append({\n",
        "                \"question\": question,\n",
        "                \"model\": model.__class__.__name__,\n",
        "                \"model_answer\": model_answer,\n",
        "                \"ground_truth\": dataset.outputs[dataset.inputs.index(item)][\"answer\"],\n",
        "                \"correct\": model_answer == dataset.outputs[dataset.inputs.index(item)][\"answer\"]\n",
        "            })\n",
        "    return results"
      ],
      "metadata": {
        "id": "3gmnVBKxDUXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the models\n",
        "models = [\n",
        "    OpenAI(model_name=\"text-davinci-003\"),  # OpenAI GPT-3.5\n",
        "    HuggingFaceHub(repo_id=\"gpt2\"),          # Example Hugging Face model\n",
        "    # Add more models as needed\n",
        "]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluation_results = evaluate_model(models, dataset)\n",
        "\n",
        "    for result in evaluation_results:\n",
        "        print(f\"Question: {result['question']}\")\n",
        "        print(f\"Model: {result['model']}\")\n",
        "        print(f\"Model Answer: {result['model_answer']}\")\n",
        "        print(f\"Ground Truth: {result['ground_truth']}\")\n",
        "        print(f\"Correct: {result['correct']}\\n\")"
      ],
      "metadata": {
        "id": "KY6wi8xYDbil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}